{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "\n",
    "to_remove = []\n",
    "d_to_remove = workbookDir\n",
    "for i, p in enumerate(sys.path):\n",
    "    try:\n",
    "        if p == \"\":\n",
    "            to_remove.append(i)\n",
    "        elif os.path.samefile(p, d_to_remove):\n",
    "            to_remove.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in reversed(to_remove):\n",
    "    try:\n",
    "        sys.path.pop(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sys.path.insert(0, \"/home/guangyunhan/onnxruntime/build_rocm/Release/build/lib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = onnx.helper.make_tensor_value_info(\"input\", onnx.TensorProto.FLOAT16, [\"batchsize\", 512, 768])\n",
    "attn_mask = onnx.helper.make_tensor_value_info(\"attn_mask\", onnx.TensorProto.INT32, [\"batchsize\", 512])\n",
    "output = onnx.helper.make_tensor_value_info(\"output\", onnx.TensorProto.FLOAT16, [\"batchsize\", 512, 768])\n",
    "\n",
    "np.random.seed(1)\n",
    "# qkv_weight = onnx.helper.make_tensor(\"qkv_weight\", onnx.TensorProto.FLOAT16, [768, 2304], np.random.randn(*[768, 2304]))\n",
    "qkv_weight = onnx.helper.make_tensor(\"qkv_weight\", onnx.TensorProto.FLOAT16, [768, 2304], np.random.normal(-7.5e-05, 0.09015, [768, 2304]))\n",
    "# qkv_weight = onnx.helper.make_tensor(\"qkv_weight\", onnx.TensorProto.FLOAT16, [768, 2304], np.zeros([768, 2304]))\n",
    "# qkv_bias = onnx.helper.make_tensor(\"qkv_bias\", onnx.TensorProto.FLOAT16, [2304], np.random.random([2304]))\n",
    "qkv_bias = onnx.helper.make_tensor(\"qkv_bias\", onnx.TensorProto.FLOAT16, [2304], np.zeros([2304]))\n",
    "\n",
    "\n",
    "\n",
    "node = onnx.helper.make_node(\"Attention\", inputs=[\"input\", \"qkv_weight\", \"qkv_bias\", \"attn_mask\"], outputs=[\"output\"], domain=\"com.microsoft\", num_heads=12)\n",
    "\n",
    "graph = onnx.helper.make_graph([node], \"Attn\", [input, attn_mask], [output], initializer=[qkv_weight, qkv_bias])\n",
    "\n",
    "model = onnx.helper.make_model(graph, producer_name=\"tmp\", opset_imports=[\n",
    "    onnx.helper.make_opsetid('com.microsoft', 1), \n",
    "    onnx.helper.make_opsetid('ai.onnx.ml', 1), \n",
    "    onnx.helper.make_opsetid('', 14),\n",
    "])\n",
    "\n",
    "print(onnx.checker.check_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = ort.InferenceSession(\n",
    "    model.SerializeToString(), providers=[\n",
    "    (\"ROCMExecutionProvider\", {\"tunable_op_enabled\": \"0\"})\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randn(64, 512, 768)\n",
    "input = input.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ORT_ATTENTION_USE_GEMM_RCR_BIAS_PERMUTE\"] = \"1\"\n",
    "os.environ[\"ORT_ATTENTION_USE_BATCHED_GEMM_SOFTMAX_GEMM_PERMUTE\"] = \"1\"\n",
    "\n",
    "o11 = sess.run(\n",
    "    output_names = [node.name for node in sess.get_outputs()],\n",
    "    input_feed = { \"input\": input, \"attn_mask\": np.ones([64, 512], dtype=np.int32)}\n",
    ")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ORT_ATTENTION_USE_GEMM_RCR_BIAS_PERMUTE\"] = \"0\"\n",
    "os.environ[\"ORT_ATTENTION_USE_BATCHED_GEMM_SOFTMAX_GEMM_PERMUTE\"] = \"1\"\n",
    "\n",
    "o01 = sess.run(\n",
    "    output_names = [node.name for node in sess.get_outputs()],\n",
    "    input_feed = { \"input\": input, \"attn_mask\": np.ones([64, 512], dtype=np.int32)}\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ORT_ATTENTION_USE_GEMM_RCR_BIAS_PERMUTE\"] = \"1\"\n",
    "os.environ[\"ORT_ATTENTION_USE_BATCHED_GEMM_SOFTMAX_GEMM_PERMUTE\"] = \"0\"\n",
    "\n",
    "o10 = sess.run(\n",
    "    output_names = [node.name for node in sess.get_outputs()],\n",
    "    input_feed = { \"input\": input, \"attn_mask\": np.ones([64, 512], dtype=np.int32)}\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ORT_ATTENTION_USE_GEMM_RCR_BIAS_PERMUTE\"] = \"0\"\n",
    "os.environ[\"ORT_ATTENTION_USE_BATCHED_GEMM_SOFTMAX_GEMM_PERMUTE\"] = \"0\"\n",
    "\n",
    "\n",
    "o00 = sess.run(\n",
    "    output_names = [node.name for node in sess.get_outputs()],\n",
    "    input_feed = { \"input\": input, \"attn_mask\": np.ones([64, 512], dtype=np.int32)}\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit _ = sess.run(output_names = [node.name for node in sess.get_outputs()], input_feed = { \"input\": input, \"attn_mask\": np.ones([64, 512], dtype=np.int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = o00\n",
    "my = o01\n",
    "diff = ref - my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref)\n",
    "print(my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = ref.copy()\n",
    "denorm[denorm == 0] = float(\"inf\")\n",
    "rtol = np.abs(diff / denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(rtol[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol_no_inf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol[2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(diff[0]) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERNEL_EXPLORER_BUILD_DIR\"] = \"/home/guangyunhan/onnxruntime/build_rocm/Release\"\n",
    "sys.path.insert(0, \"/home/guangyunhan/onnxruntime/onnxruntime/python/tools/kernel_explorer/kernels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernel_explorer as ke\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinormal_distribution(num_distribution, num_element_per_dist):\n",
    "    arrays = []\n",
    "    for i in range(num_distribution):\n",
    "        mean = np.random.randn()\n",
    "        std = np.random.rand()\n",
    "        arrays.append(np.random.normal(mean, std, (num_element_per_dist,)))\n",
    "    return np.array(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "seq_len = 512\n",
    "num_heads = 12\n",
    "head_dim = 64\n",
    "scale = 1.0\n",
    "\n",
    "np.random.seed(1)\n",
    "rand = multinormal_distribution(batchsize * num_heads * seq_len, 3 * head_dim)\n",
    "\n",
    "q = rand[:, 0*head_dim:1*head_dim].reshape(batchsize, num_heads, seq_len, head_dim)\n",
    "k = rand[:, 1*head_dim:2*head_dim].reshape(batchsize, num_heads, seq_len, head_dim)\n",
    "# v = rand[:, 2*head_dim:3*head_dim].reshape(batchsize, num_heads, seq_len, head_dim)\n",
    "v = np.random.uniform(-0.1, 0.1, (batchsize, num_heads, seq_len, head_dim))\n",
    "\n",
    "attn_before_softmax = torch.matmul(torch.Tensor(q), torch.Tensor(k).transpose(2, 3)) * scale\n",
    "attn = torch.softmax(attn_before_softmax, dim=-1)\n",
    "ref = torch.permute(torch.matmul(attn, torch.Tensor(v)), [0, 2, 1, 3]).numpy()\n",
    "\n",
    "q = q.astype(np.float16)\n",
    "k = k.astype(np.float16)\n",
    "v = v.astype(np.float16)\n",
    "my = np.zeros((batchsize, seq_len, num_heads, head_dim), dtype=np.float16)\n",
    "\n",
    "dev_q = ke.DeviceArray(q)\n",
    "dev_k = ke.DeviceArray(k)\n",
    "dev_v = ke.DeviceArray(v)\n",
    "dev_my = ke.DeviceArray(my)\n",
    "\n",
    "op = ke.BatchedGemmSoftmaxGemmPermute_half(dev_q, dev_k, dev_v, dev_my, batchsize, seq_len, num_heads, head_dim, scale)\n",
    "op.Run()\n",
    "dev_my.UpdateHostNumpyArray()\n",
    "\n",
    "diff = ref - my\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((np.abs(rtol) > 0.005)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = diff.reshape(64, 512, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(rtol) > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(diff).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol = (ref - my) / ref\n",
    "rtol = rtol.reshape(64, 512, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol.reshape(-1)[6217159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.reshape(-1)[6217159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my.reshape(-1)[6217159]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"KERNEL_EXPLORER_BUILD_DIR\"] = \"/home/guangyunhan/onnxruntime-ke/build_rocm/Release\"\n",
    "sys.path.insert(0, \"/home/guangyunhan/onnxruntime-ke/onnxruntime/python/tools/kernel_explorer/kernels\")\n",
    "\n",
    "import kernel_explorer as ke\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "M = 512\n",
    "K = 768\n",
    "N = 3072\n",
    "O = 768\n",
    "\n",
    "np.random.seed(0)\n",
    "a = 0.01 * np.random.uniform(size=(batch, M, K))\n",
    "b = 0.01 * np.random.uniform(size=(1, K, N))\n",
    "# bias = 0.1 * np.ones((N,))\n",
    "bias = 0.1 * np.zeros((M, N,))\n",
    "# bias = np.random.uniform(size=(N,))\n",
    "c = 0.1 * np.random.uniform(size=(1, N, O))\n",
    "\n",
    "ref = (a @ b + bias) @ c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(np.float16)\n",
    "b = b.astype(np.float16)\n",
    "bias = bias.astype(np.float16)\n",
    "c = c.astype(np.float16)\n",
    "my = np.zeros_like(ref, dtype=np.float16)\n",
    "\n",
    "dev_a = ke.DeviceArray(a)\n",
    "dev_b = ke.DeviceArray(b)\n",
    "dev_bias = ke.DeviceArray(bias)\n",
    "dev_c = ke.DeviceArray(c)\n",
    "dev_my = ke.DeviceArray(my)\n",
    "\n",
    "op = ke.BatchedGemmBiasGeluGemm_half(dev_a, dev_b, dev_bias, dev_c, dev_my, M, K, N, O, batch)\n",
    "op.Run()\n",
    "dev_my.UpdateHostNumpyArray()\n",
    "\n",
    "rdiff = np.abs((ref - my) / ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rdiff[-1] > 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4df2db70753b21a2efdad3d254da883dc5064407ff8f7b7e846407acb1a68d89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
